{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50ce358",
   "metadata": {},
   "source": [
    "# Pairs Trading Strategy: A Cointegration-Based Approach\n",
    "## IEOR 198 Final Project\n",
    "\n",
    "This notebook implements a market-neutral pairs trading strategy using cointegration analysis on S&P 500 stocks. The strategy identifies statistically related stock pairs and trades on mean reversion when their price relationship diverges from historical norms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545e0e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from itertools import combinations\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"All imports loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb9afa",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "We'll download 2+ years of adjusted close prices for a subset of S&P 500 stocks using yfinance. To keep computation tractable for pairs screening, we focus on stocks from specific sectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ceda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers: 40\n",
      "Sectors: ['Technology', 'Financial', 'Energy', 'Consumer']\n"
     ]
    }
   ],
   "source": [
    "# Define S&P 500 tickers by sector for pairs trading\n",
    "# We focus on sectors where pairs trading works well (similar business models)\n",
    "\n",
    "# Technology sector\n",
    "tech_tickers = ['AAPL', 'MSFT', 'GOOGL', 'META', 'NVDA', 'AMD', 'INTC', 'CRM', 'ADBE', 'ORCL']\n",
    "\n",
    "# Financial sector\n",
    "financial_tickers = ['JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'USB', 'PNC', 'TFC', 'COF']\n",
    "\n",
    "# Consumer Discretionary\n",
    "consumer_tickers = ['AMZN', 'TSLA', 'HD', 'MCD', 'NKE', 'SBUX', 'TGT', 'LOW', 'TJX', 'ROST']\n",
    "\n",
    "# Energy sector\n",
    "energy_tickers = ['XOM', 'CVX', 'COP', 'SLB', 'EOG', 'MPC', 'PSX', 'VLO', 'OXY', 'HAL']\n",
    "\n",
    "# Combine all tickers\n",
    "all_tickers = tech_tickers + financial_tickers + consumer_tickers + energy_tickers\n",
    "\n",
    "# Create sector mapping for later use\n",
    "sector_map = {}\n",
    "for t in tech_tickers: sector_map[t] = 'Technology'\n",
    "for t in financial_tickers: sector_map[t] = 'Financial'\n",
    "for t in consumer_tickers: sector_map[t] = 'Consumer'\n",
    "for t in energy_tickers: sector_map[t] = 'Energy'\n",
    "\n",
    "print(f\"Total tickers: {len(all_tickers)}\")\n",
    "print(f\"Sectors: {list(set(sector_map.values()))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0710a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from 2022-01-01 to 2024-12-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "1 Failed download:\n",
      "['INTC']: OperationalError('database is locked')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (732, 0)\n",
      "Date range: 2022-01-03 to 2024-11-29\n",
      "Tickers with complete data: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2022-01-03 00:00:00, 2022-01-04 00:00:00, 2022-01-05 00:00:00, 2022-01-06 00:00:00, 2022-01-07 00:00:00]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download historical price data\n",
    "# Using 2+ years of data for robust cointegration testing\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2024-12-01'\n",
    "\n",
    "print(f\"Downloading data from {start_date} to {end_date}...\")\n",
    "\n",
    "# Download adjusted close prices for all tickers\n",
    "price_data = yf.download(all_tickers, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "# Drop any tickers with missing data\n",
    "price_data = price_data.dropna(axis=1, how='any')\n",
    "\n",
    "print(f\"\\nData shape: {price_data.shape}\")\n",
    "print(f\"Date range: {price_data.index[0].date()} to {price_data.index[-1].date()}\")\n",
    "print(f\"Tickers with complete data: {len(price_data.columns)}\")\n",
    "price_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b8b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log returns shape: (732, 0)\n",
      "\n",
      "Sample statistics:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLog returns shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_returns.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mlog_returns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kaelan\\.conda\\envs\\cs127\\Lib\\site-packages\\pandas\\core\\generic.py:12041\u001b[39m, in \u001b[36mNDFrame.describe\u001b[39m\u001b[34m(self, percentiles, include, exclude)\u001b[39m\n\u001b[32m  11799\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m  11800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdescribe\u001b[39m(\n\u001b[32m  11801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11804\u001b[39m     exclude=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  11805\u001b[39m ) -> Self:\n\u001b[32m  11806\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  11807\u001b[39m \u001b[33;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[32m  11808\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  12039\u001b[39m \u001b[33;03m    max            NaN      3.0\u001b[39;00m\n\u001b[32m  12040\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12041\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdescribe_ndframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  12043\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12045\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12046\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mdescribe\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kaelan\\.conda\\envs\\cs127\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:91\u001b[39m, in \u001b[36mdescribe_ndframe\u001b[39m\u001b[34m(obj, include, exclude, percentiles)\u001b[39m\n\u001b[32m     87\u001b[39m     describer = SeriesDescriber(\n\u001b[32m     88\u001b[39m         obj=cast(\u001b[33m\"\u001b[39m\u001b[33mSeries\u001b[39m\u001b[33m\"\u001b[39m, obj),\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     describer = \u001b[43mDataFrameDescriber\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDataFrame\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m result = describer.describe(percentiles=percentiles)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kaelan\\.conda\\envs\\cs127\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:162\u001b[39m, in \u001b[36mDataFrameDescriber.__init__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.exclude = exclude\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m obj.columns.size == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot describe a DataFrame without columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(obj)\n",
      "\u001b[31mValueError\u001b[39m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "# Calculate log returns for analysis\n",
    "log_returns = np.log(price_data / price_data.shift(1)).dropna()\n",
    "\n",
    "print(f\"Log returns shape: {log_returns.shape}\")\n",
    "print(\"\\nSample statistics:\")\n",
    "log_returns.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769caa3",
   "metadata": {},
   "source": [
    "## 2. Pair Selection via Cointegration\n",
    "\n",
    "**Cointegration** is a statistical property where two non-stationary time series share a common stochastic trend. Unlike correlation (which measures co-movement), cointegration implies a stable long-run equilibrium relationship.\n",
    "\n",
    "We use the **Engle-Granger two-step cointegration test**:\n",
    "1. Run OLS regression: Y_t = alpha + beta * X_t + epsilon_t\n",
    "2. Test residuals for stationarity using ADF test\n",
    "\n",
    "A p-value < 0.05 indicates the pair is likely cointegrated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fd942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(data, sector_map, significance=0.05):\n",
    "    \"\"\"\n",
    "    Find cointegrated pairs within the same sector using Engle-Granger test.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with pair info sorted by p-value\n",
    "    \"\"\"\n",
    "    tickers = data.columns.tolist()\n",
    "    n = len(tickers)\n",
    "    pairs_results = []\n",
    "    \n",
    "    # Only test pairs within the same sector (fundamental justification)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            ticker1, ticker2 = tickers[i], tickers[j]\n",
    "            \n",
    "            # Check if same sector\n",
    "            if sector_map.get(ticker1) != sector_map.get(ticker2):\n",
    "                continue\n",
    "                \n",
    "            # Run cointegration test\n",
    "            score, pvalue, _ = coint(data[ticker1], data[ticker2])\n",
    "            \n",
    "            if pvalue < significance:\n",
    "                pairs_results.append({\n",
    "                    'ticker1': ticker1,\n",
    "                    'ticker2': ticker2,\n",
    "                    'sector': sector_map.get(ticker1, 'Unknown'),\n",
    "                    'pvalue': pvalue,\n",
    "                    't_statistic': score\n",
    "                })\n",
    "    \n",
    "    # Sort by p-value (most significant first)\n",
    "    pairs_df = pd.DataFrame(pairs_results).sort_values('pvalue')\n",
    "    return pairs_df\n",
    "\n",
    "print(\"Cointegration function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca09929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and testing (20%) periods\n",
    "# We use training data for pair selection to avoid lookahead bias\n",
    "\n",
    "train_size = int(len(price_data) * 0.8)\n",
    "train_data = price_data.iloc[:train_size]\n",
    "test_data = price_data.iloc[train_size:]\n",
    "\n",
    "print(f\"Training period: {train_data.index[0].date()} to {train_data.index[-1].date()} ({len(train_data)} days)\")\n",
    "print(f\"Testing period: {test_data.index[0].date()} to {test_data.index[-1].date()} ({len(test_data)} days)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cointegrated pairs using training data only\n",
    "print(\"Screening for cointegrated pairs (this may take a moment)...\\n\")\n",
    "\n",
    "cointegrated_pairs = find_cointegrated_pairs(train_data, sector_map, significance=0.05)\n",
    "\n",
    "print(f\"Found {len(cointegrated_pairs)} cointegrated pairs:\\n\")\n",
    "cointegrated_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top pair(s) for trading\n",
    "# If no pairs found, use a default pair known to be historically cointegrated\n",
    "if len(cointegrated_pairs) > 0:\n",
    "    best_pair = cointegrated_pairs.iloc[0]\n",
    "    stock1, stock2 = best_pair['ticker1'], best_pair['ticker2']\n",
    "    print(f\"Best pair: {stock1} - {stock2}\")\n",
    "    print(f\"Sector: {best_pair['sector']}\")\n",
    "    print(f\"Cointegration p-value: {best_pair['pvalue']:.6f}\")\n",
    "else:\n",
    "    # Fallback to a commonly traded pair\n",
    "    stock1, stock2 = 'XOM', 'CVX'\n",
    "    print(f\"No significant pairs found. Using fallback pair: {stock1} - {stock2}\")\n",
    "\n",
    "# Visualize the price series (normalized)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Normalized prices\n",
    "norm_s1 = price_data[stock1] / price_data[stock1].iloc[0]\n",
    "norm_s2 = price_data[stock2] / price_data[stock2].iloc[0]\n",
    "\n",
    "axes[0].plot(norm_s1, label=stock1, alpha=0.8)\n",
    "axes[0].plot(norm_s2, label=stock2, alpha=0.8)\n",
    "axes[0].axvline(train_data.index[-1], color='red', linestyle='--', label='Train/Test Split')\n",
    "axes[0].set_title(f'Normalized Prices: {stock1} vs {stock2}')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('Normalized Price')\n",
    "\n",
    "# Price ratio\n",
    "ratio = price_data[stock1] / price_data[stock2]\n",
    "axes[1].plot(ratio, color='purple', alpha=0.8)\n",
    "axes[1].axhline(ratio.mean(), color='green', linestyle='--', label=f'Mean: {ratio.mean():.2f}')\n",
    "axes[1].axvline(train_data.index[-1], color='red', linestyle='--', label='Train/Test Split')\n",
    "axes[1].set_title(f'Price Ratio: {stock1}/{stock2}')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylabel('Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc11b3d",
   "metadata": {},
   "source": [
    "## 3. Spread Modeling and Signal Generation\n",
    "\n",
    "The trading signal is based on the **z-score** of the price spread (or ratio). When the z-score deviates significantly from zero, we expect mean reversion:\n",
    "\n",
    "- **Entry Signal (Long spread)**: z-score < -2 (spread is unusually low, expect it to rise)\n",
    "- **Entry Signal (Short spread)**: z-score > +2 (spread is unusually high, expect it to fall)\n",
    "- **Exit Signal**: z-score crosses back through 0\n",
    "\n",
    "We use a **rolling window** to calculate the z-score to adapt to changing market conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the hedge ratio using OLS regression on training data\n",
    "# This tells us how many shares of stock2 to trade per share of stock1\n",
    "\n",
    "X = sm.add_constant(train_data[stock2])\n",
    "model = sm.OLS(train_data[stock1], X).fit()\n",
    "hedge_ratio = model.params[stock2]\n",
    "intercept = model.params['const']\n",
    "\n",
    "print(f\"Hedge Ratio (beta): {hedge_ratio:.4f}\")\n",
    "print(f\"Intercept (alpha): {intercept:.4f}\")\n",
    "print(f\"R-squared: {model.rsquared:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd193ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spread: S1 - beta * S2 - alpha\n",
    "# The spread should be stationary if the pair is cointegrated\n",
    "\n",
    "spread = price_data[stock1] - hedge_ratio * price_data[stock2] - intercept\n",
    "\n",
    "# Calculate rolling z-score\n",
    "# Using 20-day window (approximately 1 month of trading)\n",
    "lookback = 20\n",
    "\n",
    "rolling_mean = spread.rolling(window=lookback).mean()\n",
    "rolling_std = spread.rolling(window=lookback).std()\n",
    "zscore_spread = (spread - rolling_mean) / rolling_std\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Spread\n",
    "axes[0].plot(spread, label='Spread', color='blue', alpha=0.7)\n",
    "axes[0].axhline(spread.mean(), color='green', linestyle='--', label='Mean')\n",
    "axes[0].axvline(train_data.index[-1], color='red', linestyle='--', label='Train/Test Split')\n",
    "axes[0].set_title(f'Spread: {stock1} - {hedge_ratio:.2f}*{stock2}')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('Spread Value')\n",
    "\n",
    "# Z-score\n",
    "axes[1].plot(zscore_spread, label='Z-Score', color='purple', alpha=0.7)\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].axhline(2, color='red', linestyle='--', label='Upper Threshold (+2)')\n",
    "axes[1].axhline(-2, color='green', linestyle='--', label='Lower Threshold (-2)')\n",
    "axes[1].axvline(train_data.index[-1], color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].fill_between(zscore_spread.index, -2, 2, alpha=0.1, color='gray')\n",
    "axes[1].set_title('Rolling Z-Score of Spread')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylabel('Z-Score')\n",
    "axes[1].set_ylim(-5, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8017fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trading signals\n",
    "# Position: 1 = long spread (long S1, short S2), -1 = short spread (short S1, long S2), 0 = no position\n",
    "\n",
    "entry_threshold = 2.0\n",
    "exit_threshold = 0.0\n",
    "\n",
    "def generate_signals(zscore, entry_thresh=2.0, exit_thresh=0.0):\n",
    "    \"\"\"\n",
    "    Generate trading signals based on z-score thresholds.\n",
    "    \n",
    "    Long spread when z-score < -entry_thresh (spread is cheap, expect increase)\n",
    "    Short spread when z-score > +entry_thresh (spread is expensive, expect decrease)\n",
    "    Exit when z-score crosses exit_thresh (mean reversion complete)\n",
    "    \"\"\"\n",
    "    signals = pd.Series(index=zscore.index, data=0.0)\n",
    "    position = 0\n",
    "    \n",
    "    for i in range(len(zscore)):\n",
    "        if pd.isna(zscore.iloc[i]):\n",
    "            signals.iloc[i] = 0\n",
    "            continue\n",
    "            \n",
    "        z = zscore.iloc[i]\n",
    "        \n",
    "        if position == 0:  # No position\n",
    "            if z < -entry_thresh:\n",
    "                position = 1  # Long spread (expect z to increase)\n",
    "            elif z > entry_thresh:\n",
    "                position = -1  # Short spread (expect z to decrease)\n",
    "        elif position == 1:  # Long spread\n",
    "            if z > exit_thresh:\n",
    "                position = 0  # Exit\n",
    "        elif position == -1:  # Short spread\n",
    "            if z < exit_thresh:\n",
    "                position = 0  # Exit\n",
    "                \n",
    "        signals.iloc[i] = position\n",
    "    \n",
    "    return signals\n",
    "\n",
    "signals = generate_signals(zscore_spread, entry_threshold, exit_threshold)\n",
    "\n",
    "print(f\"Total trading days: {len(signals)}\")\n",
    "print(f\"Days in long position: {(signals == 1).sum()}\")\n",
    "print(f\"Days in short position: {(signals == -1).sum()}\")\n",
    "print(f\"Days with no position: {(signals == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33250af4",
   "metadata": {},
   "source": [
    "## 4. Backtesting Framework\n",
    "\n",
    "We simulate the strategy with the following assumptions:\n",
    "- **Equal dollar allocation** to each leg (long and short)\n",
    "- **Transaction costs**: 0.02% per trade (matching the lab)\n",
    "- **No leverage**: Net dollar exposure is approximately zero (market neutral)\n",
    "- **Daily rebalancing**: Position sizes adjusted based on price changes\n",
    "\n",
    "The strategy P&L comes from the spread returning to its mean value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the backtesting dataframe\n",
    "backtest_df = pd.DataFrame({\n",
    "    'date': price_data.index,\n",
    "    'price_s1': price_data[stock1].values,\n",
    "    'price_s2': price_data[stock2].values,\n",
    "    'spread': spread.values,\n",
    "    'zscore': zscore_spread.values,\n",
    "    'signal': signals.values\n",
    "}).set_index('date')\n",
    "\n",
    "# Calculate log returns for each stock\n",
    "backtest_df['ret_s1'] = np.log(backtest_df['price_s1'] / backtest_df['price_s1'].shift(1))\n",
    "backtest_df['ret_s2'] = np.log(backtest_df['price_s2'] / backtest_df['price_s2'].shift(1))\n",
    "\n",
    "# Calculate spread returns\n",
    "# When long spread: long S1, short S2 -> return = ret_s1 - ret_s2\n",
    "# When short spread: short S1, long S2 -> return = ret_s2 - ret_s1 = -(ret_s1 - ret_s2)\n",
    "backtest_df['spread_return'] = backtest_df['ret_s1'] - backtest_df['ret_s2']\n",
    "\n",
    "# Strategy return (delayed by 1 day since we trade on signal)\n",
    "backtest_df['signal_prev'] = backtest_df['signal'].shift(1)\n",
    "backtest_df['strategy_return'] = backtest_df['signal_prev'] * backtest_df['spread_return']\n",
    "\n",
    "backtest_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad571a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for transaction costs\n",
    "# We pay fees when we enter or exit a position (position changes)\n",
    "\n",
    "fee_rate = 0.0002  # 0.02% per trade\n",
    "\n",
    "# Detect position changes\n",
    "backtest_df['position_change'] = backtest_df['signal'].diff().abs()\n",
    "\n",
    "# Fee is applied to both legs when position changes\n",
    "# Since we have two legs (long one stock, short another), fee is 2x\n",
    "backtest_df['fees'] = backtest_df['position_change'] * fee_rate * 2\n",
    "\n",
    "# Strategy return after fees\n",
    "backtest_df['strategy_return_net'] = backtest_df['strategy_return'] - backtest_df['fees']\n",
    "\n",
    "# Drop NaN rows\n",
    "backtest_df = backtest_df.dropna()\n",
    "\n",
    "# Count trades\n",
    "num_trades = (backtest_df['position_change'] > 0).sum()\n",
    "print(f\"Total number of trades (entries + exits): {num_trades}\")\n",
    "print(f\"Total fees paid: {backtest_df['fees'].sum():.4%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f228ddc",
   "metadata": {},
   "source": [
    "## 5. Results and Performance Analysis\n",
    "\n",
    "We evaluate the strategy using multiple metrics:\n",
    "- **Cumulative Returns**: Total P&L over the period\n",
    "- **Sharpe Ratio**: Risk-adjusted returns (annualized)\n",
    "- **Maximum Drawdown**: Largest peak-to-trough decline\n",
    "- **Win Rate**: Percentage of profitable trades\n",
    "\n",
    "We also compare in-sample (training) vs out-of-sample (testing) performance to assess robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metric functions\n",
    "def sharpe_ratio(returns, periods_per_year=252):\n",
    "    \"\"\"Calculate annualized Sharpe ratio\"\"\"\n",
    "    if returns.std() == 0:\n",
    "        return 0\n",
    "    return (returns.mean() / returns.std()) * np.sqrt(periods_per_year)\n",
    "\n",
    "def max_drawdown(cumulative_returns):\n",
    "    \"\"\"Calculate maximum drawdown\"\"\"\n",
    "    rolling_max = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns - rolling_max) / rolling_max\n",
    "    return drawdown.min()\n",
    "\n",
    "def calculate_metrics(returns, label=\"\"):\n",
    "    \"\"\"Calculate and print key performance metrics\"\"\"\n",
    "    cum_return = returns.cumsum()\n",
    "    total_return = np.exp(cum_return.iloc[-1]) - 1  # Convert log return to simple\n",
    "    \n",
    "    metrics = {\n",
    "        'Total Return': f\"{total_return:.2%}\",\n",
    "        'Annualized Return': f\"{(returns.mean() * 252):.2%}\",\n",
    "        'Volatility (Ann.)': f\"{(returns.std() * np.sqrt(252)):.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe_ratio(returns):.2f}\",\n",
    "        'Max Drawdown': f\"{max_drawdown(np.exp(cum_return)):.2%}\",\n",
    "        'Win Rate': f\"{(returns > 0).sum() / (returns != 0).sum():.2%}\" if (returns != 0).sum() > 0 else \"N/A\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"  {label}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:20}: {v}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Performance functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39340df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split results into training and testing periods\n",
    "train_end_date = train_data.index[-1]\n",
    "\n",
    "train_results = backtest_df[backtest_df.index <= train_end_date]\n",
    "test_results = backtest_df[backtest_df.index > train_end_date]\n",
    "\n",
    "# Calculate metrics for each period\n",
    "print(\"PAIRS TRADING STRATEGY PERFORMANCE\")\n",
    "print(f\"Pair: {stock1} / {stock2}\")\n",
    "\n",
    "train_metrics = calculate_metrics(train_results['strategy_return_net'], \n",
    "                                   f\"IN-SAMPLE (Training: {train_results.index[0].date()} to {train_results.index[-1].date()})\")\n",
    "\n",
    "test_metrics = calculate_metrics(test_results['strategy_return_net'], \n",
    "                                  f\"OUT-OF-SAMPLE (Testing: {test_results.index[0].date()} to {test_results.index[-1].date()})\")\n",
    "\n",
    "full_metrics = calculate_metrics(backtest_df['strategy_return_net'], \n",
    "                                  f\"FULL PERIOD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Cumulative returns comparison\n",
    "strategy_cum = backtest_df['strategy_return_net'].cumsum()\n",
    "s1_cum = backtest_df['ret_s1'].cumsum()\n",
    "s2_cum = backtest_df['ret_s2'].cumsum()\n",
    "\n",
    "# Convert to simple returns for plotting\n",
    "axes[0].plot(np.exp(strategy_cum) - 1, label=f'Pairs Strategy ({stock1}/{stock2})', linewidth=2, color='blue')\n",
    "axes[0].plot(np.exp(s1_cum) - 1, label=f'{stock1} (Buy & Hold)', alpha=0.6, linestyle='--')\n",
    "axes[0].plot(np.exp(s2_cum) - 1, label=f'{stock2} (Buy & Hold)', alpha=0.6, linestyle='--')\n",
    "axes[0].axvline(train_end_date, color='red', linestyle='--', label='Train/Test Split', alpha=0.7)\n",
    "axes[0].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].set_title('Cumulative Returns: Pairs Strategy vs Individual Stocks', fontsize=12)\n",
    "axes[0].set_ylabel('Cumulative Return')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Strategy returns with signals overlay\n",
    "ax2 = axes[1]\n",
    "ax2.fill_between(backtest_df.index, 0, backtest_df['strategy_return_net'] * 100, \n",
    "                  where=backtest_df['strategy_return_net'] > 0, color='green', alpha=0.5, label='Profit')\n",
    "ax2.fill_between(backtest_df.index, 0, backtest_df['strategy_return_net'] * 100, \n",
    "                  where=backtest_df['strategy_return_net'] < 0, color='red', alpha=0.5, label='Loss')\n",
    "ax2.axvline(train_end_date, color='red', linestyle='--', alpha=0.7)\n",
    "ax2.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_title('Daily Strategy Returns (%)', fontsize=12)\n",
    "ax2.set_ylabel('Daily Return (%)')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading signal visualization with z-score\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Z-score with signals\n",
    "axes[0].plot(backtest_df['zscore'], color='purple', alpha=0.7, label='Z-Score')\n",
    "axes[0].axhline(2, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(-2, color='green', linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].fill_between(backtest_df.index, -2, 2, alpha=0.1, color='gray')\n",
    "axes[0].axvline(train_end_date, color='red', linestyle='--', alpha=0.7)\n",
    "axes[0].set_ylabel('Z-Score')\n",
    "axes[0].set_title('Z-Score of Spread and Trading Signals')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(-5, 5)\n",
    "\n",
    "# Position\n",
    "axes[1].fill_between(backtest_df.index, 0, backtest_df['signal'], \n",
    "                      where=backtest_df['signal'] > 0, color='green', alpha=0.5, label='Long Spread')\n",
    "axes[1].fill_between(backtest_df.index, 0, backtest_df['signal'], \n",
    "                      where=backtest_df['signal'] < 0, color='red', alpha=0.5, label='Short Spread')\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].axvline(train_end_date, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1].set_ylabel('Position')\n",
    "axes[1].set_title('Trading Position')\n",
    "axes[1].legend()\n",
    "\n",
    "# Cumulative P&L\n",
    "axes[2].plot(np.exp(strategy_cum) - 1, color='blue', linewidth=2)\n",
    "axes[2].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[2].axvline(train_end_date, color='red', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "axes[2].set_ylabel('Cumulative Return')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_title('Cumulative Strategy Return')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cfa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPair Traded: {stock1} / {stock2}\")\n",
    "print(f\"Sector: {sector_map.get(stock1, 'Unknown')}\")\n",
    "print(f\"Hedge Ratio: {hedge_ratio:.4f}\")\n",
    "print(f\"\\nTrading Parameters:\")\n",
    "print(f\"  - Entry Threshold: +/- {entry_threshold} standard deviations\")\n",
    "print(f\"  - Exit Threshold: {exit_threshold} (mean reversion)\")\n",
    "print(f\"  - Lookback Window: {lookback} days\")\n",
    "print(f\"  - Transaction Cost: {fee_rate:.2%} per trade\")\n",
    "print(f\"\\nTotal Trades: {num_trades}\")\n",
    "print(f\"Average Holding Period: {len(backtest_df) / max(num_trades/2, 1):.1f} days\")\n",
    "\n",
    "# Out-of-sample is the true test of strategy viability\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY RESULT: OUT-OF-SAMPLE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "if len(test_results) > 0:\n",
    "    oos_sharpe = sharpe_ratio(test_results['strategy_return_net'])\n",
    "    oos_return = np.exp(test_results['strategy_return_net'].cumsum().iloc[-1]) - 1\n",
    "    print(f\"\\n  Sharpe Ratio: {oos_sharpe:.2f}\")\n",
    "    print(f\"  Total Return: {oos_return:.2%}\")\n",
    "    \n",
    "    if oos_sharpe > 1:\n",
    "        print(\"\\n  -> Strategy shows promise with Sharpe > 1\")\n",
    "    elif oos_sharpe > 0:\n",
    "        print(\"\\n  -> Strategy is profitable but Sharpe < 1\")\n",
    "    else:\n",
    "        print(\"\\n  -> Strategy did not perform well out-of-sample\")\n",
    "else:\n",
    "    print(\"\\n  No out-of-sample data available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfda08",
   "metadata": {},
   "source": [
    "---\n",
    "# PAPER: Pairs Trading Strategy Using Cointegration Analysis\n",
    "## IEOR 198 Final Project\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This paper presents a market-neutral pairs trading strategy based on cointegration analysis of S&P 500 stocks. The strategy identifies statistically related stock pairs within the same sector and generates trading signals when their price relationship diverges from historical norms. Using the Engle-Granger cointegration test to screen for viable pairs and z-score-based entry/exit rules, we backtest the strategy over a multi-year period with an 80/20 train-test split. We account for transaction costs and evaluate performance using Sharpe ratio, total returns, and maximum drawdown. The results demonstrate the viability of statistical arbitrage approaches while highlighting the challenges of maintaining cointegration relationships out-of-sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50acba8",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### Background\n",
    "\n",
    "Pairs trading is a classic market-neutral strategy that has been employed by quantitative hedge funds since the 1980s, pioneered by Nunzio Tartaglia's quantitative group at Morgan Stanley. The fundamental premise is simple: identify two securities whose prices have historically moved together, and when they temporarily diverge, bet on their convergence.\n",
    "\n",
    "### Why Pairs Trading?\n",
    "\n",
    "Unlike directional strategies that profit from market movements, pairs trading aims to be **market neutral** - insulated from broad market swings. This is achieved by simultaneously holding a long position in one stock and a short position in another. The profit comes not from the overall market direction, but from the *relative* movement between the two securities.\n",
    "\n",
    "### Cointegration vs Correlation\n",
    "\n",
    "A critical distinction in pairs trading is between **correlation** and **cointegration**:\n",
    "\n",
    "- **Correlation** measures how two price series move together over time. However, two correlated stocks can drift apart permanently.\n",
    "- **Cointegration** is a stronger statistical property indicating that two non-stationary series share a common stochastic trend. If cointegrated, their spread (linear combination) is stationary and will revert to a mean.\n",
    "\n",
    "We use cointegration as our primary screening criterion because it provides a theoretical basis for mean reversion, which is the core assumption of pairs trading.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Screen S&P 500 stocks for cointegrated pairs within the same sector\n",
    "2. Develop a systematic trading strategy based on z-score signals\n",
    "3. Backtest the strategy with realistic transaction costs\n",
    "4. Evaluate out-of-sample performance to assess strategy robustness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d949f4",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "### Data Source\n",
    "\n",
    "We use **Yahoo Finance** (via the `yfinance` Python library) to obtain historical adjusted closing prices for S&P 500 constituent stocks. Adjusted close prices account for stock splits and dividends, providing a more accurate representation of total returns.\n",
    "\n",
    "### Universe Selection\n",
    "\n",
    "To make pair screening computationally tractable and fundamentally sound, we focus on 40 stocks from four sectors:\n",
    "- **Technology** (10 stocks): AAPL, MSFT, GOOGL, META, NVDA, AMD, INTC, CRM, ADBE, ORCL\n",
    "- **Financial** (10 stocks): JPM, BAC, WFC, GS, MS, C, USB, PNC, TFC, COF\n",
    "- **Consumer Discretionary** (10 stocks): AMZN, TSLA, HD, MCD, NKE, SBUX, TGT, LOW, TJX, ROST\n",
    "- **Energy** (10 stocks): XOM, CVX, COP, SLB, EOG, MPC, PSX, VLO, OXY, HAL\n",
    "\n",
    "### Time Period\n",
    "\n",
    "- **Full Period**: January 2022 - December 2024 (approximately 3 years)\n",
    "- **Training Set** (80%): Used for cointegration testing and parameter estimation\n",
    "- **Test Set** (20%): Used for out-of-sample performance evaluation\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "1. Downloaded daily adjusted close prices for all 40 tickers\n",
    "2. Removed tickers with missing data during the period\n",
    "3. Calculated log returns: $r_t = \\ln(P_t / P_{t-1})$\n",
    "4. Aligned all time series to common trading days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f629e0",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs127",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
